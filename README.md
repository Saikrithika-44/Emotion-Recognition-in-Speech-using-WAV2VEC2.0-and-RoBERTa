Emotion Recognition using Wav2Vec2.0 and RoBERTa

A speech emotion recognition system was developed by integrating speech-to-text transcription with emotion classification. Audio recordings from the SAVEE dataset were preprocessed through resampling and normalization to prepare inputs for the Wav2Vec2.0 model, which was employed to convert speech into text. The resulting transcriptions were then processed by a RoBERTa model for emotion classification. Both models were fine-tuned using techniques such as tokenization, attention masking, and AdamW optimization with dynamic learning rate scheduling. The systemâ€™s performance was evaluated using metrics including accuracy, precision, recall, and F1-score. Tools such as PyTorch, Hugging Face Transformers, TorchAudio, and data visualization libraries were utilized throughout the project. This approach demonstrates how speech processing and natural language understanding methods can be combined effectively for emotion recognition, with potential applications in assistive technologies and mental health monitoring.
